{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from lgg_model import *\n",
    "from gensim.models import Word2Vec\n",
    "# from translate import *\n",
    "\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_enhanced(\n",
       "  (Embedding): Embedding(3067, 256)\n",
       "  (LSTM): LSTM(256, 256, num_layers=3, batch_first=True, dropout=0.1)\n",
       "  (Linear): Linear(in_features=256, out_features=3067, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgg_model_path = input(\"è¯·è¾“å…¥æƒ³ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹(æ— éœ€æ·»åŠ åç¼€)ï¼š\")\n",
    "lgg_model_path = 'lgg_model_paths/' + lgg_model_path\n",
    "lgg_model = torch.load(lgg_model_path, map_location='cpu')\n",
    "lgg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_path = input(\"è¯·ä½¿ç”¨æƒ³ä½¿ç”¨çš„è¯æ±‡åº“(æ— éœ€æ·»åŠ åç¼€)ï¼š\")\n",
    "word_model_path = 'word_model_paths/' + word_model_path\n",
    "word_model = Word2Vec.load(word_model_path)\n",
    "wv = word_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -9.9010,  -9.7920, -10.0020,  ...,  -9.7487,  -9.9116,  -9.7439],\n",
       "        [ -3.2599,  -2.0971,  -2.6715,  ...,  -2.8029,  -3.2739,  -2.6459],\n",
       "        [ -8.4065,  -7.5731,  -7.3951,  ...,  -8.3534,  -8.0513,  -8.2858],\n",
       "        [-12.6778, -13.7086, -11.7202,  ..., -12.8463, -13.3368, -12.7257]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgg_model(torch.tensor([101, 10000, 22, 102]))['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hhhhhhç©¿ç€è½®æ»‘é‹çœ‹ä¸å‡ºæ¥å¤§å®¶ä¼šå°ç‚¹ç‚¹çš„ä½œå­äº†ï¼Œç„¶åç»©ç‚¹å¯„äº†\n",
      "[Hans] dzè¿™è¾¹ç¼ºä¹äº¤æµ\n",
      "[Bob] Re æ´ä¸»: å®Œäº†ï¼Œè¶Šè¯´è¶Šåƒæˆ‘çš„æ¶ˆæ¯?\n",
      "[Carol] Re æ´ä¸»: é€Ÿé€ŸğŸ¤º\n",
      "[æ´ä¸»] Re Bob: è€ƒè¯•\n",
      "[Hans] Re Francis: 163 17  jyï¼Œçº¯å±soâ€†ritent&ä¸ªæ´é‡Œé‚£é‡Œï¼Œè¿™å­¦æœŸæœ‰çŠ¹è±«è¿‡è¥¿éŸ³å’Œæµªæ¬§ï¼Œä½†æ˜¯æˆ‘è§‰å¾—å¤§å®¶å¯ä»¥åƒç‰¹åˆ«å’Œè°çš„ç”·ç”Ÿçš„ğŸ˜£ï¼Œå°±æ˜¯è¯´äº†è‡ªå·±å’Œå¯¹æ–¹è¯´åŒæ€§å§\n",
      "Generation finished.\n"
     ]
    }
   ],
   "source": [
    "words = input(\"è¯·è¾“å…¥åˆå§‹æ–‡æœ¬ï¼š\")\n",
    "del_lst = []\n",
    "lst = list(words)\n",
    "\n",
    "for i in lst:\n",
    "    if i not in wv.key_to_index:\n",
    "        del_lst.append(i)\n",
    "for i in del_lst:\n",
    "    lst.remove(i)\n",
    "\n",
    "data = np.array([])\n",
    "for i in lst:\n",
    "    data = np.append(data, wv.key_to_index[i])\n",
    "\n",
    "count = int(input(\"è¯·è¾“å…¥æƒ³è¦ç”Ÿæˆçš„å­—(è¯)æ•°ï¼š\"))\n",
    "\n",
    "for i in lst:\n",
    "    print(i, end='')\n",
    "\n",
    "for i in range(count):\n",
    "    data = np.stack((data,))\n",
    "    x = torch.Tensor(data)\n",
    "    x = x.to(torch.long)\n",
    "    y = lgg_model(x)[0][-1]\n",
    "    p = y.detach().numpy()\n",
    "    p = softmax(p)\n",
    "\n",
    "    idx = np.random.choice(np.arange(len(wv)), p=p)\n",
    "    new_word = wv.index_to_key[idx]\n",
    "    print(new_word, end='')\n",
    "\n",
    "    lst.append(new_word)\n",
    "    data = np.append(data, idx)\n",
    "\n",
    "print('\\nGeneration finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"GPT-2 model generation\"\"\"\n",
    "\"\"\"æ²¡ç”¨ï¼å‡€ç»™æˆ‘æŠ¥é”™ï¼\"\"\"\n",
    "words = input(\"è¯·è¾“å…¥åˆå§‹æ–‡æœ¬ï¼š\")\n",
    "del_lst = []\n",
    "lst = list(words)\n",
    "\n",
    "data = []\n",
    "data.append(101)\n",
    "for i in lst:\n",
    "    data.append(tokenizer.encode(i)[1])\n",
    "data.append(102)\n",
    "data = torch.tensor(data)\n",
    "print(data)\n",
    "print(lgg_model(data)[0][-1])\n",
    "\n",
    "count = int(input(\"è¯·è¾“å…¥æƒ³è¦ç”Ÿæˆçš„å­—(è¯)æ•°ï¼š\"))\n",
    "\n",
    "for i in lst:\n",
    "    print(i, end='')\n",
    "\n",
    "for i in range(count):\n",
    "    y = lgg_model(data)[0][-1]\n",
    "    p = y.detach()\n",
    "    p = torch.softmax(p, dim=0)\n",
    "\n",
    "    idx = np.random.choice(tokenizer.vocab_size, p=np.array(p))\n",
    "    new_word = tokenizer.decode(idx)\n",
    "    print(new_word, end='')\n",
    "\n",
    "    lst.append(new_word)\n",
    "    data = torch.hstack((data, torch.tensor([idx])))\n",
    "\n",
    "print('\\nGeneration finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate the generated text into classical Chinese\n",
    "to_be_translated = str(lst)\n",
    "translated = inference(to_be_translated)\n",
    "for i in translated[0]:\n",
    "    print(i, end='')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
